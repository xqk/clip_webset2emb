{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install clip-inference"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 加载google drive"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "## 初始化集合"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from clip_inference.dataset import Dataset\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset_name = \"zhukeai_medias\"\n",
    "dataset_dir = \"dataset\"\n",
    "clip_cache_path = '/content/drive/MyDrive/colab/model/'\n",
    "clip_model = \"cn_clip:ViT-H-14\"\n",
    "if not os.path.exists(clip_cache_path):\n",
    "  os.makedirs(clip_cache_path)\n",
    "\n",
    "dataset = Dataset(\n",
    "     dataset_name,\n",
    "     dataset_dir,\n",
    "     clip_model,\n",
    "     clip_cache_path,\n",
    "     image_size=336,\n",
    "     output_format=\"webdataset\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 下载图片并提取特征"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"/content/drive/MyDrive/colab/archilovers/urls/images.parquet\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_urls = []\n",
    "for v in df.itertuples():\n",
    "  all_urls.append({\n",
    "      \"url\": v.url,\n",
    "      \"caption\": \"\"\n",
    "  })\n",
    "len(all_urls), all_urls[:2]\n",
    "\n",
    "start = 0\n",
    "end = 4000\n",
    "\n",
    "all_urls = all_urls[start:end]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "if os.path.exists(\"/content/drive/MyDrive/colab/archilovers/emb\"):\n",
    "    os.makedirs(\"/content/drive/MyDrive/colab/archilovers/emb\")\n",
    "\n",
    "def to_emb(offset, limit):\n",
    "  backup_name = f\"{offset}-{limit}\"\n",
    "  backup_dir = f\"/content/drive/MyDrive/colab/archilovers/emb/{backup_name}\"\n",
    "  if os.path.exists(backup_dir):\n",
    "    return\n",
    "\n",
    "  urls = all_urls[offset: offset + limit]\n",
    "\n",
    "  # urls2parquet\n",
    "  dataset.urls2parquet(urls)\n",
    "\n",
    "  # parquet2webdataset\n",
    "  dataset.parquet2webdataset()\n",
    "\n",
    "  # webdataset2inference_by_files\n",
    "  start_num = 0  # 起始文件编号\n",
    "  end_num = 2  # 结束文件编号\n",
    "  webdataset_dir = f\"/content/{dataset_dir}/images/{dataset_name}\"\n",
    "  embeddings_folder = f\"/content/{dataset_dir}/embeddings/{dataset_name}\"\n",
    "  urls_parquet = f\"/content/{dataset_dir}/urls/{dataset_name}.parquet\"\n",
    "  input_files = [f\"{webdataset_dir}/{str(x).zfill(5)}.tar\"  for x in list(range(start_num, end_num + 1)) if os.path.exists(f\"{webdataset_dir}/{str(x).zfill(5)}.tar\")]\n",
    "  batch_size = 512\n",
    "  start = time.time()\n",
    "  dataset.webdataset2inference_by_files(input_files, embeddings_folder, batch_size)\n",
    "  print(\"耗时（秒）:\", time.time() - start)\n",
    "\n",
    "  # 备份文件并删除源文件\n",
    "  shutil.copytree(f\"{embeddings_folder}\", backup_dir)\n",
    "  shutil.rmtree(webdataset_dir)\n",
    "  shutil.rmtree(embeddings_folder)\n",
    "  os.remove(urls_parquet)\n",
    "\n",
    "\n",
    "limit = 1000\n",
    "page_size = int(math.ceil(len(all_urls) / limit))\n",
    "for i in tqdm(range(page_size)):\n",
    "  to_emb(i * limit, limit)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
